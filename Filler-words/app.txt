from flask import Flask, request, jsonify
import librosa, joblib, numpy as np
from feature_extractor import extract_features

app = Flask(__name__)
model = joblib.load("filler_detector_model.pkl")

@app.route("/predict", methods=["POST"])
def predict():
    try:
        print("âœ… Request received at /predict")

        if 'audio' not in request.files:
            return jsonify({"error": "No audio file found"}), 400

        file = request.files["audio"]
        print(f"ðŸ“„ File received: {file.filename}")
        print(f"ðŸ“„ Content type: {file.content_type}")

        temp_path = "temp_audio.wav"
        file.save(temp_path)
        print(f"âœ… Saved file to {temp_path}")

        y, sr = librosa.load(temp_path, sr=16000)
        chunk_duration_sec = 1.0
        chunk_size = int(chunk_duration_sec * sr)

        filler_count = 0
        total_chunks = 0

        # Split into chunks and predict on each
        for i in range(0, len(y), chunk_size):
            chunk = y[i:i + chunk_size]

            # Skip too short chunks (less than 0.3 sec)
            if len(chunk) < int(0.3 * sr):
                continue

            features = extract_features(chunk, sr)
            if features is None:
                continue

            prediction = model.predict([features])[0]
            total_chunks += 1
            if prediction == 1:
                filler_count += 1

        print(f"\nâœ… Total chunks analyzed: {total_chunks}")
        print(f"ðŸ—£ï¸ Estimated filler words in clip: {filler_count}")

        return jsonify({
            "filler_prediction": filler_count,
            "total_chunks": total_chunks,
            "message": f"Filler word count detected: {filler_count}"
        })

    except Exception as e:
        print("âŒ Error in Flask /predict:", str(e))
        return jsonify({"error": str(e)}), 500

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5001)